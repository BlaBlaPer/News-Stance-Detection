{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2, 3 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Done in previous notebook\n",
    "2. Extract vector representation of headlines and bodies in the all the datasets, and compute the cosine similarity between these two vectors. You can use representations based on bag-of- words or other methods like Word2Vec for vector based representations. You are encouraged to explore alternative representations as well.\n",
    "3. Establish language model based representations of the headlines and the article bodies in all the datasets and calculate the KL-divergence for each pair of headlines and article bodies. Feel free to explore different smoothing techniques for language model based representations.\n",
    "4. Propose and implement alternative features/distances that might be helpful for the stance detection task. Describe feature meaning and extraction process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "- In this notebook, task 2, 3 and task 4 have been implemented\n",
    "The output contains two csv files: \n",
    "1. Word2vec vector representations (accociasted with cosine similarities), named (Headline_w2c_vec, Body_w2c_vec separately) \n",
    "2. Tfidf vector representations (accociasted with cosine similarities), named (Headline_tfidf_vec, Body_tfidf_vec separately) \n",
    "\n",
    " The word2vec model is trained by using all the sentences in the trainning set. \n",
    "\n",
    " The TF-IDF model is trained by using all the unique sentences in the trainning set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Name List\n",
    "1. Train_stance and Train_body :original table (49972 stance(head), 1683 body)\n",
    "   Pred_headline and Pred_body are the preprocessed versions of Train_stance and Train_body (49972 (head), 1683 body)\n",
    "2. Train_df: merged Train_stance and Train_bidy (49972 haed + 49972 body)\n",
    "4. All sentence: all sentences of headline and body (not unique 99444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import re\n",
    "\n",
    "#import libraries for data processing\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#import libraries for vectorisation\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#train validation set split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#cosice distance\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "\n",
    "#Counter for count word frequency\n",
    "from collections import Counter\n",
    "\n",
    "#import tqdm for feature construction\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "sns.set_style(\"white\")  \n",
    "\n",
    "#math for calculation\n",
    "import math\n",
    "\n",
    "\n",
    "#import the training set and test set\n",
    "Train_body = pd.read_csv('/Users/weisihan/Downloads/fnc-1-master/train_bodies.csv')\n",
    "Train_stance = pd.read_csv('/Users/weisihan/Downloads/fnc-1-master/train_stances.csv')\n",
    "Test_body = pd.read_csv('/Users/weisihan/Downloads/fnc-1-master/competition_test_bodies.csv')\n",
    "Test_stance = pd.read_csv('/Users/weisihan/Downloads/fnc-1-master/competition_test_stances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Extract vector representation of headlines and bodies, compute the cosine similarity between these two vectors. \n",
    "You can use representations based on bag-of-words or other methods like Word2Vec for vector based representations. You are encouraged to explore alternative representations as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before doing that, we should preprocess the training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading English stopwords\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "the preprocessing will be don in the following step:\n",
    "1. select only the english word, filter out numbers, punctuations, etc\n",
    "2. split each piece of data (either headline or body) and get each single word\n",
    "3. transform each word into lower case\n",
    "4. transform the plurals into singluar\n",
    "4. delete english stop words. eg. is, a, the ...\n",
    "5. join each word again to get piece of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising fuction for text processing (we only get alphabetic characters, lowercase and remove stopwords)\n",
    "def preprocessing(data, col):\n",
    "    df=data.copy()\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    table = []\n",
    "    table = [re.sub(\"[^a-zA-Z]\", \" \",str(dt)) for dt in df[col]]#save only english words,delete numbers, punctuations,..., return list of strings\n",
    "    table = [word_tokenize(dt) for dt in table]#split the strings and get each single word e.g. [['it', 'is', 'a', 'good', 'sunny','day'],['how','are','you']...]\n",
    "    table = [[word.lower() for word in dt] for dt in table]#return the lower case\n",
    "    table = [[WordNetLemmatizer().lemmatize(word) for word in dt] for dt in table]#return the singular case\n",
    "    table = [[word for word in dt if word not in stopWords] for dt in table]#delete stop words...to remove all common pronouns (\"a\", \"the\", ...) to reduce the number of noisy features\n",
    "    table = [' '.join(word) for word in table]#use space to join the single words together again []\n",
    "    df[col] = table# make it to a column of a datafram\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do preprocessing of the training set and test set \n",
    "Pred_Train_stance = preprocessing(Train_stance,'Headline')\n",
    "Pred_Train_body = preprocessing(Train_body,'articleBody')\n",
    "Pred_Test_stance = preprocessing(Test_stance,'Headline')\n",
    "Pred_Test_body = preprocessing(Test_body,'articleBody')\n",
    "#Pred_Train_stance has a shape of (49972, 3)\n",
    "#Pred_Train_body has a shape of (1683, 2)\n",
    "#Pred_Test_stance has a shape of (25413, 3)\n",
    "#Pred_Test_body has a shape of (904, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graf least body near mexico t...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hundred palestinian flee flood gaza israel ope...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christian bale pass role steve job actor repor...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hbo apple talk month apple tv streaming servic...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spider burrowed tourist stomach chest</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  police find mass graf least body near mexico t...      712  unrelated\n",
       "1  hundred palestinian flee flood gaza israel ope...      158      agree\n",
       "2  christian bale pass role steve job actor repor...      137  unrelated\n",
       "3  hbo apple talk month apple tv streaming servic...     1034  unrelated\n",
       "4              spider burrowed tourist stomach chest     1923   disagree"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the Train Stance dataset after data preprocessing\n",
    "Pred_Train_stance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>small meteorite crashed wooded area nicaragua ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>last week hinted wa come ebola fear spread acr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>newser wonder long quarter pounder cheese last...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>posting photo gun toting child online isi supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>least suspected boko haram insurgent killed cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  small meteorite crashed wooded area nicaragua ...\n",
       "1        4  last week hinted wa come ebola fear spread acr...\n",
       "2        5  newser wonder long quarter pounder cheese last...\n",
       "3        6  posting photo gun toting child online isi supp...\n",
       "4        7  least suspected boko haram insurgent killed cl..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the Train body set after data preprocessing\n",
    "Pred_Train_body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49972, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the name of trainingset column 'Body ID' to 'Body_ID'\n",
    "Pred_Train_stance.rename(columns={'Body ID':'Body_ID'}, inplace=True) \n",
    "Pred_Train_body.rename(columns={'Body ID':'Body_ID'}, inplace=True) \n",
    "#Merge table Train_stance and Train_body\n",
    "Pred_Train_df = pd.merge(Pred_Train_stance, Pred_Train_body, how='inner', on=\"Body_ID\",  copy=True)  \n",
    "#Change the sequence of column for better view hehe\n",
    "Pred_Train_df=Pred_Train_df[['Headline', 'Body_ID', 'articleBody','Stance']]\n",
    "Pred_Train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25413, 4)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the name of testset column 'Body ID' to 'Body_ID'\n",
    "Pred_Test_stance.rename(columns={'Body ID':'Body_ID'}, inplace=True) \n",
    "Pred_Test_body.rename(columns={'Body ID':'Body_ID'}, inplace=True) \n",
    "#Merge table Test_stance and Train_body\n",
    "Pred_Test_df = pd.merge(Pred_Test_stance, Pred_Test_body, how='inner', on=\"Body_ID\",  copy=True)  \n",
    "#Change the sequence of column for better view hehe\n",
    "Pred_Test_df=Pred_Test_df[['Headline', 'Body_ID', 'articleBody','Stance']]\n",
    "Pred_Test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graf least body near mexico t...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seth rogen play apple steve wozniak</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico police find mass grave near site studen...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico say missing student found first mass graf</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new io bug delete icloud document</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  police find mass graf least body near mexico t...      712   \n",
       "1                seth rogen play apple steve wozniak      712   \n",
       "2  mexico police find mass grave near site studen...      712   \n",
       "3   mexico say missing student found first mass graf      712   \n",
       "4                  new io bug delete icloud document      712   \n",
       "\n",
       "                                         articleBody     Stance  \n",
       "0  danny boyle directing untitled film seth rogen...  unrelated  \n",
       "1  danny boyle directing untitled film seth rogen...    discuss  \n",
       "2  danny boyle directing untitled film seth rogen...  unrelated  \n",
       "3  danny boyle directing untitled film seth rogen...  unrelated  \n",
       "4  danny boyle directing untitled film seth rogen...  unrelated  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_Train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - 1 - Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Headline_list = (Pred_Train_df['Headline'].str.split()).values.tolist()\n",
    "Body_list = (Pred_Train_df['articleBody'].str.split()).values.tolist()\n",
    "\n",
    "All_sentence = np.concatenate([Headline_list, Body_list])\n",
    "#the length of All_sentence (headline+body) is 99944, not unique but all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graf least body near mexico t...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seth rogen play apple steve wozniak</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico police find mass grave near site studen...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico say missing student found first mass graf</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new io bug delete icloud document</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  police find mass graf least body near mexico t...      712   \n",
       "1                seth rogen play apple steve wozniak      712   \n",
       "2  mexico police find mass grave near site studen...      712   \n",
       "3   mexico say missing student found first mass graf      712   \n",
       "4                  new io bug delete icloud document      712   \n",
       "\n",
       "                                         articleBody     Stance  \n",
       "0  danny boyle directing untitled film seth rogen...  unrelated  \n",
       "1  danny boyle directing untitled film seth rogen...    discuss  \n",
       "2  danny boyle directing untitled film seth rogen...  unrelated  \n",
       "3  danny boyle directing untitled film seth rogen...  unrelated  \n",
       "4  danny boyle directing untitled film seth rogen...  unrelated  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build model (this is to use all sentences in the training set : 99444)\n",
    "model = gensim.models.word2vec.Word2Vec(sentences=All_sentence, min_count=1)\n",
    "words = list(model.wv.vocab.keys()) #unique words in training set (including body and headline)\n",
    "model.save('word2vec_all_sentence_99444.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute the Headline vector list based on word2vec \n",
    "Headline_w2c_vec = np.zeros((len(Headline_list), 100))\n",
    "\n",
    "for h in range(len(Headline_list)):\n",
    "    for w in Headline_list[h]:\n",
    "        if w in words:                                                        #the vector representation of the whole sentence is to add the vectors of each word in this sentenct \n",
    "            Headline_w2c_vec[h] = np.add(Headline_w2c_vec[h], model.wv.word_vec(w)) #model.wv.word_vec(w)is to search for the vector of word w\n",
    "    Headline_w2c_vec[h] = Headline_w2c_vec[h] / np.sqrt(Headline_w2c_vec[h].dot(Headline_w2c_vec[h]))  #take the normalised vector as vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute the Body vector list based on word2vec \n",
    "Body_w2c_vec = np.zeros((len(Body_list), 100))\n",
    "\n",
    "for b in range(len(Body_list)):\n",
    "    for w in Body_list[b]:\n",
    "        if w in words:\n",
    "            Body_w2c_vec[b] = np.add(Body_w2c_vec[b], model.wv.word_vec(w))\n",
    "    Body_w2c_vec[b] = Body_w2c_vec[b] / np.sqrt(Body_w2c_vec[b].dot(Body_w2c_vec[b]))#within 1\n",
    "#15:55-max:13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the word2vec represented training set headline vectors and body vectors into local files\n",
    "np.savetxt('Headline_w2c_vec', Headline_w2c_vec, delimiter=',')\n",
    "np.savetxt('Body_w2c_vec', Body_w2c_vec, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load word2vec directly\n",
    "\"\"\"\n",
    "Headline_w2c_vec = np.loadtxt('Headline_w2c_vec', dtype='float32', delimiter=',')\n",
    "Body_w2c_vec = np.loadtxt('Body_w2c_vec', dtype='float32', delimiter=',')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weisihan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#Use the trained model to compute the vectors for the test set\n",
    "\n",
    "Test_Headline_list = (Pred_Test_df['Headline'].str.split()).values.tolist()\n",
    "Test_Body_list = (Pred_Test_df['articleBody'].str.split()).values.tolist()\n",
    "\n",
    "Test_Headline_w2c_vec = np.zeros((len(Test_Headline_list), 100))\n",
    "\n",
    "for h in range(len(Test_Headline_list)):\n",
    "    for w in Test_Headline_list[h]:\n",
    "        if w in words:                                                        #the vector representation of the whole sentence is to add the vectors of each word in this sentenct \n",
    "            Test_Headline_w2c_vec[h] = np.add(Test_Headline_w2c_vec[h], model.wv.word_vec(w)) #model.wv.word_vec(w)is to search for the vector of word w\n",
    "    Test_Headline_w2c_vec[h] = Test_Headline_w2c_vec[h] / np.sqrt(Test_Headline_w2c_vec[h].dot(Test_Headline_w2c_vec[h]))  #take the normalised vector as vector representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute the Body vector list based on word2vec \n",
    "Test_Body_w2c_vec = np.zeros((len(Test_Body_list), 100))\n",
    "\n",
    "for b in range(len(Test_Body_list)):\n",
    "    for w in Test_Body_list[b]:\n",
    "        if w in words:\n",
    "            Test_Body_w2c_vec[b] = np.add(Test_Body_w2c_vec[b], model.wv.word_vec(w))\n",
    "    Test_Body_w2c_vec[b] = Test_Body_w2c_vec[b] / np.sqrt(Test_Body_w2c_vec[b].dot(Test_Body_w2c_vec[b]))#within 1\n",
    "#20:28-max:13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the word2vec represented testset headline vectors and body vectors into local files\n",
    "np.savetxt('Test_Headline_w2c_vec', Test_Headline_w2c_vec, delimiter=',')\n",
    "np.savetxt('Test_Body_w2c_vec', Test_Body_w2c_vec, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - 2 - TF - IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len_doc=len(All_sentence_count)\n",
    "def tf(word, count):\n",
    "    return count[word] / sum(count.values())\n",
    "\n",
    "def n_containing(word, count_list):\n",
    "    return sum(1 for count in count_list if word in count)\n",
    "\n",
    "def idf(word, count_list):\n",
    "    return math.log(len(count_list) / (1 + n_containing(word, count_list)))\n",
    "\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising fuction for selecting unique headlines and article bodies words, return the unique string list and the number of unique words\n",
    "def get_uni_strs(data):\n",
    "    uni_str = []\n",
    "    for eachstr in data:\n",
    "        if eachstr not in uni_str:\n",
    "            uni_str.append(eachstr)  \n",
    "    return uni_str\n",
    "# uni_str should be sth like: ['this is news head1','this is news head2',...,'this is body1','this is body2',...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_dict_to_vector(tfidf, inx_voc):\n",
    "    vector = np.zeros(len(inx_voc))\n",
    "    for w,t in tfidf.items():\n",
    "        if w in inx_tvoc:\n",
    "            inx_w = inx_voc[w]\n",
    "            vector[inx_w] = t\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get the list of Headlines and bodies\n",
    "Headline_list_tfidf = (Pred_Train_stance['Headline'].str.split()).values.tolist()\n",
    "Body_list_tfidf = (Pred_Train_body['articleBody'].str.split()).values.tolist()\n",
    "\n",
    "All_sentence_tfidf = np.concatenate([Headline_list_tfidf, Body_list_tfidf])\n",
    "#the length of All_sentence_tfidf (headline+body) is 51655, the initial size of train_stance ans trian_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51655"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(All_sentence_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get unique headlines and bodies from the training set\n",
    "All_sentence_unique = get_uni_strs(All_sentence_tfidf)\n",
    "#get counters of unique headlines and unique bodies from the training set, Counter() is used to count the number of apperence of each word in a piece of string\n",
    "#All_sentence_unique_count is the countlist...\n",
    "All_sentence_unique_count = [Counter(strs) for strs in All_sentence_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get counters of all headlines in the training set (49972)\n",
    "Headline_list_count = [Counter(strs) for strs in Headline_list_tfidf]\n",
    "#get counters of all bodies in the training set (1683)\n",
    "Body_list_count = [Counter(strs) for strs in Body_list_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute the tfidf for each headline and body\n",
    "Headline_tfidf=[{word: tfidf(word, count, All_sentence_unique_count) for word in count}  for count in Headline_list_count]\n",
    "#23:30-23:33\n",
    "#16:28-16:31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Body_tfidf=[{word: tfidf(word, count, All_sentence_unique_count) for word in count}  for count in Body_list_count]\n",
    "#00ï¼š44-00:46\n",
    "#16:32-16:34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19984"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_uni_words = []\n",
    "waste=[All_uni_words.extend(item) for item in All_sentence_unique]\n",
    "All_uni_words=set(All_uni_words)\n",
    "len(All_uni_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add index\n",
    "inx_tvoc = dict(zip(All_uni_words,range(len(All_uni_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Body_tfidf_vec = [tfidf_dict_to_vector(tfidfs,inx_tvoc) for tfidfs in Body_tfidf]\n",
    "Headline_tfidf_vec = [tfidf_dict_to_vector(tfidfs,inx_tvoc) for tfidfs in Headline_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmpb= Pred_Train_body.copy()\n",
    "tmph= Pred_Train_stance.copy()\n",
    "tmpb['tfidf_body'] = Body_tfidf_vec\n",
    "tmph['tfidf_head'] = Headline_tfidf_vec\n",
    " \n",
    "#Merge table Train_stance and Train_body\n",
    "tmpcomb = pd.merge(tmph, tmpb, how='inner', on=\"Body_ID\",  copy=True)  \n",
    "tmpcomb.shape\n",
    "\n",
    "#get the 49972 body tfidf vector\n",
    "Body_tfidf_vec=list(tmpcomb['tfidf_body'])\n",
    "Headline_tfidf_vec = list(tmpcomb['tfidf_head'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use the trained tfidf model to compute the vectors for the test set\n",
    "\n",
    "#get the list of Headlines and bodies\n",
    "Test_Headline_list_tfidf = (Pred_Test_stance['Headline'].str.split()).values.tolist()\n",
    "Test_Body_list_tfidf = (Pred_Test_body['articleBody'].str.split()).values.tolist()\n",
    "\n",
    "Test_All_sentence_tfidf = np.concatenate([Test_Headline_list_tfidf, Test_Body_list_tfidf])\n",
    "#the length of Test_All_sentence_tfidf (headline+body) is 26317, the initial size of test_stance and test_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26317"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Test_All_sentence_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get counters of all headlines in the test set (25413)\n",
    "Test_Headline_list_count = [Counter(strs) for strs in Test_Headline_list_tfidf]\n",
    "#get counters of all bodies in the test set (904)\n",
    "Test_Body_list_count = [Counter(strs) for strs in Test_Body_list_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute the tfidf for each headline and body in the test set\n",
    "Test_Headline_tfidf=[{word: tfidf(word, count, All_sentence_unique_count) for word in count}  for count in Test_Headline_list_count]\n",
    "#20:40-20:42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_Body_tfidf=[{word: tfidf(word, count, All_sentence_unique_count) for word in count}  for count in Test_Body_list_count]\n",
    "#20:42-20:43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_Body_tfidf_vec = [tfidf_dict_to_vector(tfidfs,inx_tvoc) for tfidfs in Test_Body_tfidf]\n",
    "Test_Headline_tfidf_vec = [tfidf_dict_to_vector(tfidfs,inx_tvoc) for tfidfs in Test_Headline_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmpb= Pred_Test_body.copy()\n",
    "tmph= Pred_Test_stance.copy()\n",
    "tmpb['tfidf_body'] = Test_Body_tfidf_vec\n",
    "tmph['tfidf_head'] = Test_Headline_tfidf_vec\n",
    " \n",
    "#Merge table Train_stance and Train_body\n",
    "tmpcomb = pd.merge(tmph, tmpb, how='inner', on=\"Body_ID\",  copy=True)  \n",
    "tmpcomb.shape\n",
    "\n",
    "#get the 49972 body tfidf vector\n",
    "Test_Body_tfidf_vec=list(tmpcomb['tfidf_body'])\n",
    "Test_Headline_tfidf_vec = list(tmpcomb['tfidf_head'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Establish language model based representations of the headlines and the article bodies in all the datasets and calculate the KL-divergence for each pair of headlines and article bodies. \n",
    "Feel free to explore different smoothing techniques for language model based representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement Language Model and Calculate KL Divergence\n",
    "def language_model(headline, body):\n",
    "    row_vocab_dict={}\n",
    "    for x in headline:\n",
    "        row_vocab_dict[x]=0\n",
    "    for x in body:\n",
    "        row_vocab_dict[x]=0\n",
    "    #dictionary of all unique words in a pair of headline and body\n",
    "    \n",
    "    headline_dict=row_vocab_dict.copy()\n",
    "    #dictionary for counting words in headline\n",
    "    articleBody_dict=row_vocab_dict.copy()\n",
    "    #dictionary for counting words in body\n",
    "    \n",
    "    for x in headline:\n",
    "        headline_dict[x]+=1\n",
    "    #count frequency for every word in headline\n",
    "    for x in body:\n",
    "        articleBody_dict[x]+=1\n",
    "    #count frequency for every word in body\n",
    "    \n",
    "    #Lapalace smoothing\n",
    "    for key in headline_dict:\n",
    "        headline_dict[key]=(headline_dict[key]+0.1)/(len(headline)+0.1*len(headline_dict))\n",
    "        #calculate probability for each unique word in heading\n",
    "        #use lapalace smoothing\n",
    "    for key in articleBody_dict:\n",
    "        articleBody_dict[key]=(articleBody_dict[key]+0.1)/(len(body)+0.1*len(articleBody_dict))\n",
    "        #calculate probability for the each unique word in body\n",
    "        #use lapalace smoothing\n",
    "        \n",
    "    #calculate kl_divergence\n",
    "    headline_list=[]\n",
    "    articleBody_list=[]\n",
    "    for key in row_vocab_dict:\n",
    "        headline_list.append(headline_dict[key])\n",
    "        articleBody_list.append(articleBody_dict[key])\n",
    "        \n",
    "    headline_vector=np.array(headline_list)\n",
    "    articleBody_vector=np.array(articleBody_list)\n",
    "    \n",
    "    kl_divergence=np.sum(headline_vector*np.log(headline_vector/articleBody_vector))\n",
    "    \n",
    "    return kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LM_kld=[language_model(h,b) for h,b in zip(Headline_list,Body_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pred_Train_df['LM_kld']=LM_kld\n",
    "Pred_Train_df.to_csv('Pred_Train_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Test_LM_kld=[language_model(h,b) for h,b in zip(Test_Headline_list,Test_Body_list)]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pred_Test_df['LM_kld']=Test_LM_kld\n",
    "Pred_Test_df.to_csv('Pred_Test_features.csv', encoding='utf-8', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Propose and implement alternative features/distances that might be helpful for the stance detection task. \n",
    "Describe feature meaning and extraction process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 1. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24361682,  0.85103494, -0.17421353, ...,  0.7424047 ,\n",
       "        0.80527228,  0.90500337], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_w2v = 1 - paired_cosine_distances(Headline_w2c_vec, Body_w2c_vec)\n",
    "cos_sim_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.22044605e-16,   3.30128623e-01,  -2.22044605e-16, ...,\n",
       "         5.90225677e-01,   3.25946275e-01,   4.26769007e-01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_tfidf=1 - paired_cosine_distances(Headline_tfidf_vec,Body_tfidf_vec)\n",
    "cos_sim_tfidf\n",
    "#17:00-17:05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "      <th>cos_sim_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graf least body near mexico t...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.243617</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seth rogen play apple steve wozniak</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>0.851035</td>\n",
       "      <td>3.301286e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico police find mass grave near site studen...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.174214</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico say missing student found first mass graf</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.041024</td>\n",
       "      <td>2.126375e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new io bug delete icloud document</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.318279</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  police find mass graf least body near mexico t...      712   \n",
       "1                seth rogen play apple steve wozniak      712   \n",
       "2  mexico police find mass grave near site studen...      712   \n",
       "3   mexico say missing student found first mass graf      712   \n",
       "4                  new io bug delete icloud document      712   \n",
       "\n",
       "                                         articleBody     Stance  cos_sim_w2v  \\\n",
       "0  danny boyle directing untitled film seth rogen...  unrelated    -0.243617   \n",
       "1  danny boyle directing untitled film seth rogen...    discuss     0.851035   \n",
       "2  danny boyle directing untitled film seth rogen...  unrelated    -0.174214   \n",
       "3  danny boyle directing untitled film seth rogen...  unrelated    -0.041024   \n",
       "4  danny boyle directing untitled film seth rogen...  unrelated     0.318279   \n",
       "\n",
       "   cos_sim_tfidf  \n",
       "0  -2.220446e-16  \n",
       "1   3.301286e-01  \n",
       "2  -2.220446e-16  \n",
       "3   2.126375e-02  \n",
       "4   0.000000e+00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_Train_df['cos_sim_w2v']=cos_sim_w2v\n",
    "Pred_Train_df['cos_sim_tfidf']=cos_sim_tfidf\n",
    "Pred_Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25401375, -0.19543733,  0.49107634, ...,  0.1641917 ,\n",
       "       -0.01334122,  0.38916749])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate features for the test set\n",
    "t_cos_sim_w2v = 1 - paired_cosine_distances(np.nan_to_num(Test_Headline_w2c_vec), Test_Body_w2c_vec)\n",
    "t_cos_sim_w2v\n",
    "t_cos_sim_tfidf = 1 - paired_cosine_distances(Test_Headline_tfidf_vec, Test_Body_tfidf_vec)\n",
    "t_cos_sim_tfidf\n",
    "#21:12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "      <th>cos_sim_tfidf</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ferguson riot pregnant woman loses eye cop fir...</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.254014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple store install safe secure gold apple watch</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.195437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pregnant woman loses eye police shoot bean bag</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>6.354246e-02</td>\n",
       "      <td>0.491076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>found ferguson protester claim wa shot eye rub...</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2.141642e-02</td>\n",
       "      <td>0.341024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>police chief charge paris attack commits suicide</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>1.742968e-01</td>\n",
       "      <td>0.628163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  ferguson riot pregnant woman loses eye cop fir...     2008   \n",
       "1   apple store install safe secure gold apple watch     2008   \n",
       "2     pregnant woman loses eye police shoot bean bag     2008   \n",
       "3  found ferguson protester claim wa shot eye rub...     2008   \n",
       "4   police chief charge paris attack commits suicide     2008   \n",
       "\n",
       "                                         articleBody     Stance  \\\n",
       "0  respected senior french police officer investi...  unrelated   \n",
       "1  respected senior french police officer investi...  unrelated   \n",
       "2  respected senior french police officer investi...  unrelated   \n",
       "3  respected senior french police officer investi...  unrelated   \n",
       "4  respected senior french police officer investi...    discuss   \n",
       "\n",
       "   cos_sim_tfidf  cos_sim_w2v  \n",
       "0   2.220446e-16     0.254014  \n",
       "1   0.000000e+00    -0.195437  \n",
       "2   6.354246e-02     0.491076  \n",
       "3   2.141642e-02     0.341024  \n",
       "4   1.742968e-01     0.628163  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_Test_df['cos_sim_tfidf']=t_cos_sim_tfidf\n",
    "Pred_Test_df['cos_sim_w2v']=t_cos_sim_w2v\n",
    "Pred_Test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 2. Word Overlap Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_overlap_features(headlines, bodies):\n",
    "    X = []\n",
    "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
    "        clean_headline = word_tokenize(headline)\n",
    "        clean_body = word_tokenize(body)\n",
    "        features = [\n",
    "            len(set(clean_headline).intersection(clean_body)) / float(len(set(clean_headline).union(clean_body)))]\n",
    "        X.append(features)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49972it [00:59, 837.46it/s]\n"
     ]
    }
   ],
   "source": [
    "overlap=word_overlap_features(Pred_Train_df['Headline'],Pred_Train_df['articleBody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_overlap=[]\n",
    "waste=[pred_overlap.extend(ovr) for ovr in overlap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "      <th>cos_sim_tfidf</th>\n",
       "      <th>overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graf least body near mexico t...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.243617</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seth rogen play apple steve wozniak</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>0.851035</td>\n",
       "      <td>3.301286e-01</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico police find mass grave near site studen...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.174214</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico say missing student found first mass graf</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.041024</td>\n",
       "      <td>2.126375e-02</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new io bug delete icloud document</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.318279</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  police find mass graf least body near mexico t...      712   \n",
       "1                seth rogen play apple steve wozniak      712   \n",
       "2  mexico police find mass grave near site studen...      712   \n",
       "3   mexico say missing student found first mass graf      712   \n",
       "4                  new io bug delete icloud document      712   \n",
       "\n",
       "                                         articleBody     Stance  cos_sim_w2v  \\\n",
       "0  danny boyle directing untitled film seth rogen...  unrelated    -0.243617   \n",
       "1  danny boyle directing untitled film seth rogen...    discuss     0.851035   \n",
       "2  danny boyle directing untitled film seth rogen...  unrelated    -0.174214   \n",
       "3  danny boyle directing untitled film seth rogen...  unrelated    -0.041024   \n",
       "4  danny boyle directing untitled film seth rogen...  unrelated     0.318279   \n",
       "\n",
       "   cos_sim_tfidf   overlap  \n",
       "0  -2.220446e-16  0.000000  \n",
       "1   3.301286e-01  0.065217  \n",
       "2  -2.220446e-16  0.000000  \n",
       "3   2.126375e-02  0.020408  \n",
       "4   0.000000e+00  0.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_Train_df['overlap']=pred_overlap\n",
    "Pred_Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pred_Train_df.to_csv('Pred_Train_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25413it [00:29, 867.72it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"t_overlap=word_overlap_features(Pred_Test_df['Headline'],Pred_Test_df['articleBody'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"t_pred_overlap=[]\n",
    "waste=[t_pred_overlap.extend(ovr) for ovr in t_overlap]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "      <th>cos_sim_tfidf</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "      <th>overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ferguson riot pregnant woman loses eye cop fir...</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.254014</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple store install safe secure gold apple watch</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.195437</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pregnant woman loses eye police shoot bean bag</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>6.354246e-02</td>\n",
       "      <td>0.491076</td>\n",
       "      <td>0.007407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>found ferguson protester claim wa shot eye rub...</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2.141642e-02</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>police chief charge paris attack commits suicide</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>1.742968e-01</td>\n",
       "      <td>0.628163</td>\n",
       "      <td>0.022727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  ferguson riot pregnant woman loses eye cop fir...     2008   \n",
       "1   apple store install safe secure gold apple watch     2008   \n",
       "2     pregnant woman loses eye police shoot bean bag     2008   \n",
       "3  found ferguson protester claim wa shot eye rub...     2008   \n",
       "4   police chief charge paris attack commits suicide     2008   \n",
       "\n",
       "                                         articleBody     Stance  \\\n",
       "0  respected senior french police officer investi...  unrelated   \n",
       "1  respected senior french police officer investi...  unrelated   \n",
       "2  respected senior french police officer investi...  unrelated   \n",
       "3  respected senior french police officer investi...  unrelated   \n",
       "4  respected senior french police officer investi...    discuss   \n",
       "\n",
       "   cos_sim_tfidf  cos_sim_w2v   overlap  \n",
       "0   2.220446e-16     0.254014  0.000000  \n",
       "1   0.000000e+00    -0.195437  0.000000  \n",
       "2   6.354246e-02     0.491076  0.007407  \n",
       "3   2.141642e-02     0.341024  0.021739  \n",
       "4   1.742968e-01     0.628163  0.022727  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Pred_Test_df['overlap']=t_pred_overlap\n",
    "Pred_Test_df.head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pred_Test_df.to_csv('Pred_Test_features.csv', encoding='utf-8', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 2. Word Polarity Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polarity_features(headlines, bodies):\n",
    "    _refuting_words = [\n",
    "        'fake',\n",
    "        'fraud',\n",
    "        'hoax',\n",
    "        'false',\n",
    "        'deny', 'denies',\n",
    "        'not',\n",
    "        'despite',\n",
    "        'nope',\n",
    "        'doubt', 'doubts',\n",
    "        'bogus',\n",
    "        'debunk',\n",
    "        'pranks',\n",
    "        'retract'\n",
    "    ]\n",
    "\n",
    "    def calculate_polarity(text):\n",
    "        tokens = word_tokenize(text)\n",
    "        return sum([t in _refuting_words for t in tokens]) % 2\n",
    "    X = []\n",
    "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
    "        features = []\n",
    "        features.append(calculate_polarity(headline))\n",
    "        features.append(calculate_polarity(body))\n",
    "        X.append(features)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49972it [00:58, 848.95it/s]\n"
     ]
    }
   ],
   "source": [
    "polar=polarity_features(Pred_Train_df['Headline'],Pred_Train_df['articleBody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pred_Train_df['polar_h']=polar[:,0]\n",
    "Pred_Train_df['polar_b']=polar[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "      <th>cos_sim_tfidf</th>\n",
       "      <th>overlap</th>\n",
       "      <th>polar_h</th>\n",
       "      <th>polar_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graf least body near mexico t...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.243617</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seth rogen play apple steve wozniak</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>0.851035</td>\n",
       "      <td>3.301286e-01</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico police find mass grave near site studen...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.174214</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico say missing student found first mass graf</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.041024</td>\n",
       "      <td>2.126375e-02</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new io bug delete icloud document</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.318279</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  police find mass graf least body near mexico t...      712   \n",
       "1                seth rogen play apple steve wozniak      712   \n",
       "2  mexico police find mass grave near site studen...      712   \n",
       "3   mexico say missing student found first mass graf      712   \n",
       "4                  new io bug delete icloud document      712   \n",
       "\n",
       "                                         articleBody     Stance  cos_sim_w2v  \\\n",
       "0  danny boyle directing untitled film seth rogen...  unrelated    -0.243617   \n",
       "1  danny boyle directing untitled film seth rogen...    discuss     0.851035   \n",
       "2  danny boyle directing untitled film seth rogen...  unrelated    -0.174214   \n",
       "3  danny boyle directing untitled film seth rogen...  unrelated    -0.041024   \n",
       "4  danny boyle directing untitled film seth rogen...  unrelated     0.318279   \n",
       "\n",
       "   cos_sim_tfidf   overlap  polar_h  polar_b  \n",
       "0  -2.220446e-16  0.000000        0        0  \n",
       "1   3.301286e-01  0.065217        0        0  \n",
       "2  -2.220446e-16  0.000000        0        0  \n",
       "3   2.126375e-02  0.020408        0        0  \n",
       "4   0.000000e+00  0.000000        0        0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pred_Train_df.to_csv('Pred_Train_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25413it [00:30, 846.93it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"t_polar=polarity_features(Pred_Test_df['Headline'],Pred_Test_df['articleBody'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pred_Test_df['polar_h']=t_polar[:,0]\n",
    "Pred_Test_df['polar_b']=t_polar[:,1]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pred_Test_df.to_csv('Pred_Test_features.csv', encoding='utf-8', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 3. Refuting Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def refuting_features(headlines, bodies):\n",
    "    _refuting_words = [\n",
    "        'fake',\n",
    "        'fraud',\n",
    "        'hoax',\n",
    "        'false',\n",
    "        'deny', 'denies',\n",
    "        # 'refute',\n",
    "        'not',\n",
    "        'despite',\n",
    "        'nope',\n",
    "        'doubt', 'doubts',\n",
    "        'bogus',\n",
    "        'debunk',\n",
    "        'pranks',\n",
    "        'retract'\n",
    "    ]\n",
    "    X = []\n",
    "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
    "        clean_headline = word_tokenize(headline)\n",
    "        features = [1 if word in clean_headline else 0 for word in _refuting_words]\n",
    "        X.append(features)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49972it [00:06, 7345.60it/s]\n"
     ]
    }
   ],
   "source": [
    "#Currently dont know how to use this feature\n",
    "refute=refuting_features(Pred_Train_df['Headline'],Pred_Train_df['articleBody'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 4. Pearson Correlation Coeffcient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# use equation to calculate Pearson Correlation Coefficients \\n\\ndef PearsonCorr(Head,Body):\\n    corr=[]\\n    for x, y in zip(Head,Body):\\n        x_=x-np.mean(x)\\n        y_=y-np.mean(y)\\n        d2=np.dot(x_,y_)/(np.linalg.norm(x_)*np.linalg.norm(y_))\\n        corr.append(d2)\\n    return corr\\n\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the pearson correlation coefficient in this array\n",
    "def PearsonCorr(Head,Body):\n",
    "    corr=[]\n",
    "    for x, y in zip(Head, Body):\n",
    "        X=np.vstack([x,y])\n",
    "        d1=np.corrcoef(X)[0][1]\n",
    "        corr.append(d1)\n",
    "    return corr\n",
    "\n",
    "\"\"\"\n",
    "# use equation to calculate Pearson Correlation Coefficients \n",
    "\n",
    "def PearsonCorr(Head,Body):\n",
    "    corr=[]\n",
    "    for x, y in zip(Head,Body):\n",
    "        x_=x-np.mean(x)\n",
    "        y_=y-np.mean(y)\n",
    "        d2=np.dot(x_,y_)/(np.linalg.norm(x_)*np.linalg.norm(y_))\n",
    "        corr.append(d2)\n",
    "    return corr\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_Cor_Coe_w2c = PearsonCorr(Headline_w2c_vec, Body_w2c_vec)\n",
    "P_Cor_Coe_tfidf = PearsonCorr(Headline_tfidf_vec, Body_tfidf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "      <th>cos_sim_tfidf</th>\n",
       "      <th>overlap</th>\n",
       "      <th>polar_h</th>\n",
       "      <th>polar_b</th>\n",
       "      <th>P_Cor_Coe_w2c</th>\n",
       "      <th>P_Cor_Coe_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graf least body near mexico t...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.243617</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.234044</td>\n",
       "      <td>-0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seth rogen play apple steve wozniak</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>0.851035</td>\n",
       "      <td>3.301286e-01</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.849136</td>\n",
       "      <td>0.329755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico police find mass grave near site studen...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.174214</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162194</td>\n",
       "      <td>-0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico say missing student found first mass graf</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.041024</td>\n",
       "      <td>2.126375e-02</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036997</td>\n",
       "      <td>0.020160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new io bug delete icloud document</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.318279</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.316359</td>\n",
       "      <td>-0.001007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  police find mass graf least body near mexico t...      712   \n",
       "1                seth rogen play apple steve wozniak      712   \n",
       "2  mexico police find mass grave near site studen...      712   \n",
       "3   mexico say missing student found first mass graf      712   \n",
       "4                  new io bug delete icloud document      712   \n",
       "\n",
       "                                         articleBody     Stance  cos_sim_w2v  \\\n",
       "0  danny boyle directing untitled film seth rogen...  unrelated    -0.243617   \n",
       "1  danny boyle directing untitled film seth rogen...    discuss     0.851035   \n",
       "2  danny boyle directing untitled film seth rogen...  unrelated    -0.174214   \n",
       "3  danny boyle directing untitled film seth rogen...  unrelated    -0.041024   \n",
       "4  danny boyle directing untitled film seth rogen...  unrelated     0.318279   \n",
       "\n",
       "   cos_sim_tfidf   overlap  polar_h  polar_b  P_Cor_Coe_w2c  P_Cor_Coe_tfidf  \n",
       "0  -2.220446e-16  0.000000        0        0      -0.234044        -0.001445  \n",
       "1   3.301286e-01  0.065217        0        0       0.849136         0.329755  \n",
       "2  -2.220446e-16  0.000000        0        0      -0.162194        -0.001232  \n",
       "3   2.126375e-02  0.020408        0        0      -0.036997         0.020160  \n",
       "4   0.000000e+00  0.000000        0        0       0.316359        -0.001007  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_Train_df['P_Cor_Coe_w2c']=P_Cor_Coe_w2c\n",
    "Pred_Train_df['P_Cor_Coe_tfidf']=P_Cor_Coe_tfidf\n",
    "Pred_Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pred_Train_df.to_csv('Pred_Train_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weisihan/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:3003: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/weisihan/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:3004: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test_P_Cor_Coe_w2c = PearsonCorr(Test_Headline_w2c_vec, Test_Body_w2c_vec)\n",
    "Test_P_Cor_Coe_tfidf = PearsonCorr(Test_Headline_tfidf_vec, Test_Body_tfidf_vec)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "      <th>cos_sim_tfidf</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "      <th>overlap</th>\n",
       "      <th>polar_h</th>\n",
       "      <th>polar_b</th>\n",
       "      <th>P_Cor_Coe_w2c</th>\n",
       "      <th>P_Cor_Coe_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ferguson riot pregnant woman loses eye cop fir...</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.254014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254075</td>\n",
       "      <td>-0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple store install safe secure gold apple watch</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.195437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.195883</td>\n",
       "      <td>-0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pregnant woman loses eye police shoot bean bag</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>6.354246e-02</td>\n",
       "      <td>0.491076</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491410</td>\n",
       "      <td>0.062481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>found ferguson protester claim wa shot eye rub...</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2.141642e-02</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341870</td>\n",
       "      <td>0.020011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>police chief charge paris attack commits suicide</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>1.742968e-01</td>\n",
       "      <td>0.628163</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.628161</td>\n",
       "      <td>0.173617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  ferguson riot pregnant woman loses eye cop fir...     2008   \n",
       "1   apple store install safe secure gold apple watch     2008   \n",
       "2     pregnant woman loses eye police shoot bean bag     2008   \n",
       "3  found ferguson protester claim wa shot eye rub...     2008   \n",
       "4   police chief charge paris attack commits suicide     2008   \n",
       "\n",
       "                                         articleBody     Stance  \\\n",
       "0  respected senior french police officer investi...  unrelated   \n",
       "1  respected senior french police officer investi...  unrelated   \n",
       "2  respected senior french police officer investi...  unrelated   \n",
       "3  respected senior french police officer investi...  unrelated   \n",
       "4  respected senior french police officer investi...    discuss   \n",
       "\n",
       "   cos_sim_tfidf  cos_sim_w2v   overlap  polar_h  polar_b  P_Cor_Coe_w2c  \\\n",
       "0   2.220446e-16     0.254014  0.000000        0        0       0.254075   \n",
       "1   0.000000e+00    -0.195437  0.000000        0        0      -0.195883   \n",
       "2   6.354246e-02     0.491076  0.007407        0        0       0.491410   \n",
       "3   2.141642e-02     0.341024  0.021739        1        0       0.341870   \n",
       "4   1.742968e-01     0.628163  0.022727        0        0       0.628161   \n",
       "\n",
       "   P_Cor_Coe_tfidf  \n",
       "0        -0.001565  \n",
       "1        -0.001134  \n",
       "2         0.062481  \n",
       "3         0.020011  \n",
       "4         0.173617  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Pred_Test_df['P_Cor_Coe_w2c']=np.nan_to_num(Test_P_Cor_Coe_w2c)\n",
    "Pred_Test_df['P_Cor_Coe_tfidf']=np.nan_to_num(Test_P_Cor_Coe_tfidf)\n",
    "Pred_Test_df.head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pred_Test_df.to_csv('Pred_Test_features.csv', encoding='utf-8', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 5. Euclidean Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Euclidean_distance(Head, Body):\n",
    "    Euc_dis=[]\n",
    "    for x, y in zip(Head, Body):\n",
    "        d1=np.sqrt(np.sum(np.square(x-y)))\n",
    "        Euc_dis.append(d1)\n",
    "    return Euc_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Euc_distance_w2c = Euclidean_distance(Headline_w2c_vec, Body_w2c_vec)\n",
    "Euc_distance_tfidf = Euclidean_distance(Headline_tfidf_vec, Body_tfidf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "      <th>cos_sim_tfidf</th>\n",
       "      <th>overlap</th>\n",
       "      <th>polar_h</th>\n",
       "      <th>polar_b</th>\n",
       "      <th>P_Cor_Coe_w2c</th>\n",
       "      <th>P_Cor_Coe_tfidf</th>\n",
       "      <th>Euc_distance_w2c</th>\n",
       "      <th>Euc_distance_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graf least body near mexico t...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.243617</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.234044</td>\n",
       "      <td>-0.001445</td>\n",
       "      <td>1.577097</td>\n",
       "      <td>1.117929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seth rogen play apple steve wozniak</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>0.851035</td>\n",
       "      <td>3.301286e-01</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.849136</td>\n",
       "      <td>0.329755</td>\n",
       "      <td>0.545830</td>\n",
       "      <td>1.447857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico police find mass grave near site studen...</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.174214</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162194</td>\n",
       "      <td>-0.001232</td>\n",
       "      <td>1.532458</td>\n",
       "      <td>1.333335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mexico say missing student found first mass graf</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>-0.041024</td>\n",
       "      <td>2.126375e-02</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036997</td>\n",
       "      <td>0.020160</td>\n",
       "      <td>1.442931</td>\n",
       "      <td>1.244375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new io bug delete icloud document</td>\n",
       "      <td>712</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.318279</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.316359</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>1.167665</td>\n",
       "      <td>1.941065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  police find mass graf least body near mexico t...      712   \n",
       "1                seth rogen play apple steve wozniak      712   \n",
       "2  mexico police find mass grave near site studen...      712   \n",
       "3   mexico say missing student found first mass graf      712   \n",
       "4                  new io bug delete icloud document      712   \n",
       "\n",
       "                                         articleBody     Stance  cos_sim_w2v  \\\n",
       "0  danny boyle directing untitled film seth rogen...  unrelated    -0.243617   \n",
       "1  danny boyle directing untitled film seth rogen...    discuss     0.851035   \n",
       "2  danny boyle directing untitled film seth rogen...  unrelated    -0.174214   \n",
       "3  danny boyle directing untitled film seth rogen...  unrelated    -0.041024   \n",
       "4  danny boyle directing untitled film seth rogen...  unrelated     0.318279   \n",
       "\n",
       "   cos_sim_tfidf   overlap  polar_h  polar_b  P_Cor_Coe_w2c  P_Cor_Coe_tfidf  \\\n",
       "0  -2.220446e-16  0.000000        0        0      -0.234044        -0.001445   \n",
       "1   3.301286e-01  0.065217        0        0       0.849136         0.329755   \n",
       "2  -2.220446e-16  0.000000        0        0      -0.162194        -0.001232   \n",
       "3   2.126375e-02  0.020408        0        0      -0.036997         0.020160   \n",
       "4   0.000000e+00  0.000000        0        0       0.316359        -0.001007   \n",
       "\n",
       "   Euc_distance_w2c  Euc_distance_tfidf  \n",
       "0          1.577097            1.117929  \n",
       "1          0.545830            1.447857  \n",
       "2          1.532458            1.333335  \n",
       "3          1.442931            1.244375  \n",
       "4          1.167665            1.941065  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_Train_df['Euc_distance_w2c']=Euc_distance_w2c\n",
    "Pred_Train_df['Euc_distance_tfidf']=Euc_distance_tfidf\n",
    "Pred_Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pred_Train_df.to_csv('Pred_Train_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Test_Euc_distance_w2c = Euclidean_distance(Test_Headline_w2c_vec, Test_Body_w2c_vec)\n",
    "Test_Euc_distance_tfidf = Euclidean_distance(Test_Headline_tfidf_vec, Test_Body_tfidf_vec)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Stance</th>\n",
       "      <th>cos_sim_tfidf</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "      <th>overlap</th>\n",
       "      <th>polar_h</th>\n",
       "      <th>polar_b</th>\n",
       "      <th>P_Cor_Coe_w2c</th>\n",
       "      <th>P_Cor_Coe_tfidf</th>\n",
       "      <th>Euc_distance_w2c</th>\n",
       "      <th>Euc_distance_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ferguson riot pregnant woman loses eye cop fir...</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.254014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254075</td>\n",
       "      <td>-0.001565</td>\n",
       "      <td>1.221463</td>\n",
       "      <td>1.370576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple store install safe secure gold apple watch</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.195437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.195883</td>\n",
       "      <td>-0.001134</td>\n",
       "      <td>1.546245</td>\n",
       "      <td>1.482062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pregnant woman loses eye police shoot bean bag</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>6.354246e-02</td>\n",
       "      <td>0.491076</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491410</td>\n",
       "      <td>0.062481</td>\n",
       "      <td>1.008884</td>\n",
       "      <td>1.686966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>found ferguson protester claim wa shot eye rub...</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2.141642e-02</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341870</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>1.148021</td>\n",
       "      <td>1.011718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>police chief charge paris attack commits suicide</td>\n",
       "      <td>2008</td>\n",
       "      <td>respected senior french police officer investi...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>1.742968e-01</td>\n",
       "      <td>0.628163</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.628161</td>\n",
       "      <td>0.173617</td>\n",
       "      <td>0.862365</td>\n",
       "      <td>1.309439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID  \\\n",
       "0  ferguson riot pregnant woman loses eye cop fir...     2008   \n",
       "1   apple store install safe secure gold apple watch     2008   \n",
       "2     pregnant woman loses eye police shoot bean bag     2008   \n",
       "3  found ferguson protester claim wa shot eye rub...     2008   \n",
       "4   police chief charge paris attack commits suicide     2008   \n",
       "\n",
       "                                         articleBody     Stance  \\\n",
       "0  respected senior french police officer investi...  unrelated   \n",
       "1  respected senior french police officer investi...  unrelated   \n",
       "2  respected senior french police officer investi...  unrelated   \n",
       "3  respected senior french police officer investi...  unrelated   \n",
       "4  respected senior french police officer investi...    discuss   \n",
       "\n",
       "   cos_sim_tfidf  cos_sim_w2v   overlap  polar_h  polar_b  P_Cor_Coe_w2c  \\\n",
       "0   2.220446e-16     0.254014  0.000000        0        0       0.254075   \n",
       "1   0.000000e+00    -0.195437  0.000000        0        0      -0.195883   \n",
       "2   6.354246e-02     0.491076  0.007407        0        0       0.491410   \n",
       "3   2.141642e-02     0.341024  0.021739        1        0       0.341870   \n",
       "4   1.742968e-01     0.628163  0.022727        0        0       0.628161   \n",
       "\n",
       "   P_Cor_Coe_tfidf  Euc_distance_w2c  Euc_distance_tfidf  \n",
       "0        -0.001565          1.221463            1.370576  \n",
       "1        -0.001134          1.546245            1.482062  \n",
       "2         0.062481          1.008884            1.686966  \n",
       "3         0.020011          1.148021            1.011718  \n",
       "4         0.173617          0.862365            1.309439  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Pred_Test_df['Euc_distance_w2c']=Test_Euc_distance_w2c\n",
    "Pred_Test_df['Euc_distance_tfidf']=Test_Euc_distance_tfidf\n",
    "Pred_Test_df.head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pred_Test_df.to_csv('Pred_Test_features.csv', encoding='utf-8', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 6. KL Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the KL Divergence only works for positive probabilities, we only use tfidf in this part to calculate KL divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KL(P,Q):\n",
    "    P = np.array(P)\n",
    "    Q = np.array(Q)\n",
    "    sum = []\n",
    "    for i in range(len(P)):\n",
    "        if P[i] == 0 and Q[i] == 0:\n",
    "            continue\n",
    "        p=P[i]+np.spacing(1) \n",
    "        q=Q[i]+np.spacing(1)\n",
    "        sum.append(p * (math.log(p / q)))\n",
    "    all_value= [x for x in sum]# delete nan of inf\n",
    "    return np.sum(all_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Asymmetric\n",
    "kl_dis_HB= [KL(h,b) for h, b in zip(Headline_tfidf_vec,Body_tfidf_vec)]\n",
    "#19:04-19:08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Asymmetric\n",
    "kl_dis_BH=[KL(b,h) for h, b in zip(Headline_tfidf_vec,Body_tfidf_vec)]\n",
    "#19:10-19:15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Symmetric\n",
    "kl_dis = [(kl_dis_HB[i]+kl_dis_BH[i])/2 for i in range(len(kl_dis_HB))]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pred_Train_df['kl_dis']=kl_dis_HB\n",
    "Pred_Train_df.to_csv('Pred_Train_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"t_kl_dis_HB= [KL(h,b) for h, b in zip(Test_Headline_tfidf_vec,Test_Body_tfidf_vec)]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"t_kl_dis_BH=[KL(b,h) for h, b in zip(Test_Headline_tfidf_vec,Test_Body_tfidf_vec)]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"t_kl_dis = [(t_kl_dis_HB[i]+t_kl_dis_BH[i])/2 for i in range(len(t_kl_dis_HB))]  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pred_Test_df['kl_dis']=t_kl_dis_HB\n",
    "Pred_Test_df.to_csv('Pred_Test_features.csv', encoding='utf-8', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
